# Repeatability of the Imaging Stack Regression

This document establishes that the imaging stack regression documented in this repository is **repeatable** and **state-dependent**, not a one-off anomaly.

The purpose of this document is to demonstrate that the behavior follows a consistent pattern when the same class of workload is executed under comparable conditions on Windows 11 Insider Canary builds.

This is a post-resolution finding. The system was already restored to a clean Canary baseline prior to these observations.

---

## Scope

This document focuses on repeatability only.

It does not re-litigate:
- Root cause theory
- Canary or CFR background
- Recovery or re-baselining procedures

Those topics are documented elsewhere in this repository:

- Root cause theory and platform interpretation:  
  [`03.CANARY_RESEARCH_SOURCES.md`](./03.CANARY_RESEARCH_SOURCES.md)

- Workload characteristics and stress profile:  
  [`04.INFERENCE_LOAD_CHARACTERISTICS.md`](./04.INFERENCE_LOAD_CHARACTERISTICS.md)

- Recovery and re-baselining procedures:  
  [`05.BASELINING_EXPLAINED.md`](./05.BASELINING_EXPLAINED.md)  
  [`06.RECOVERY_PROCESS_SOFTLOCK.md`](./06.RECOVERY_PROCESS_SOFTLOCK.md)

---

## Summary of Repeatable Behavior

Across multiple sessions on a clean Canary baseline, the regression reappears after executing workloads that share the following characteristics:

- SDXL-class inference workloads
- Long-lived CUDA contexts
- GPU passthrough via WSL2
- High VRAM and BAR1 pressure
- High prompt token density
- Non-canonical image resolutions
- Repeated transitions between compute and desktop usage

The system remains stable during inference and fails only after returning to routine desktop imaging tasks.

---

## Observed Trigger Sequence

The following sequence has been observed repeatedly:

1. Extended SDXL inference runs complete successfully
2. GPU utilization returns to idle
3. Desktop usage resumes
4. Screenshot capture or image viewing is attempted
5. Imaging tools fail immediately

This sequence has occurred more than once under the same workload profile.

<img width="588" height="682" alt="image" src="https://github.com/user-attachments/assets/e8046bb4-93c6-4f94-a488-4b1464a61c97" />

---

## What Repeatability Confirms

Repeatability confirms that:

- The workload itself is valid
- Inference execution is not failing
- The failure is post-workload, not during compute
- The regression is stateful and cumulative
- The issue is not caused by configuration drift or user error

This behavior aligns with Canary experimentation affecting shared runtime paths rather than application-level logic.

---

## Why Repeatability Matters

Repeatability elevates this issue from anecdotal to investigable.

It enables:
- Meaningful comparison across Canary builds
- Validation by other advanced users
- Tracking of regression persistence over time
- Clear separation between transient glitches and systemic behavior

This is a defining property of a real platform regression.

---

## Visual Signals Observed Prior to Regression

Before the imaging stack regression fully manifests, visual anomalies begin to appear in generated outputs.

These artifacts were not initially recognized as errors. In retrospect, they represent early indicators of GPU or runtime instability preceding the regression.

The images below were generated successfully and written to disk. They are included here as **observational evidence**, not as proof of causality.

---

### Representative Pre-Regression Outputs

The following images were produced during sustained SDXL inference runs shortly before the regression reappeared.

They exhibit visual corruption patterns inconsistent with prompt intent or model behavior.

#### Example 1
![Pre-regression visual artifact](docs/images/00465-2026-01-16-TempestV0.1-Artistic.jpg)

#### Example 2
![Pre-regression visual artifact](docs/images/00460-2026-01-16-TempestV0.1-Artistic.jpg)

#### Example 3
![Pre-regression visual artifact](docs/images/00461-2026-01-16-TempestV0.1-Artistic.jpg)

#### Example 4
![Pre-regression visual artifact](docs/images/00469-2026-01-16-TempestV0.1-Artistic.jpg)

#### Example 5
![Pre-regression visual artifact](docs/images/00470-2026-01-16-TempestV0.1-Artistic.jpg)

#### Example 6
![Pre-regression visual artifact](docs/images/00463-2026-01-16-TempestV0.1-Artistic.jpg)

---

## Interpretation of These Artifacts

These images share several important characteristics:

- Inference completed without error
- Files were fully written and readable
- Corruption appears localized and non-random
- Visual defects persist across multiple generations
- The anomalies increase in frequency leading up to regression onset

This strongly suggests that these artifacts are **symptomatic of a degrading runtime state**, not model instability or prompt misuse.

---

## Why These Images Matter

These visual anomalies appear **before** desktop imaging failure occurs.

They likely indicate:

- Memory allocator stress
- Tensor or buffer corruption
- Synchronization breakdowns between compute and graphics paths
- Early GPU state incoherence

While the exact mechanism is unknown, the timing is consistent:

> Visual corruption appears first  
> Imaging tools fail later  

This makes these images useful as **early warning signals** when operating under the described workload class.

---

## Important Limitation

These images do **not** prove root cause.

They are included to document **observable symptoms** that correlate with the regressionâ€™s return, enabling:

- Earlier detection
- Improved workload hygiene
- Cross-system comparison by other advanced users

They should be interpreted as signals, not conclusions.


---

## Current Status

At the time of writing:

- The regression is repeatable under the described workload class
- It is recoverable without re-baselining (see mitigation document)
- It is not deterministic on first occurrence
- It appears cumulative and state-driven

Future Canary updates may alter or eliminate this behavior. Until then, repeatability remains an important signal.
